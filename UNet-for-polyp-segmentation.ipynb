{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1786115,"sourceType":"datasetVersion","datasetId":1061766},{"sourceId":6880424,"sourceType":"datasetVersion","datasetId":3953190}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nfrom glob import glob\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:45:34.814384Z","iopub.execute_input":"2024-08-16T11:45:34.815360Z","iopub.status.idle":"2024-08-16T11:45:52.226724Z","shell.execute_reply.started":"2024-08-16T11:45:34.815313Z","shell.execute_reply":"2024-08-16T11:45:52.225580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_img = cv2.imread(\"/kaggle/input/kvasir-seg/Kvasir-SEG/images/cju0qkwl35piu0993l0dewei2.jpg\") #3 channels / spectral bands\nplt.imshow(temp_img)\ntemp_img.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:45:52.228656Z","iopub.execute_input":"2024-08-16T11:45:52.229420Z","iopub.status.idle":"2024-08-16T11:45:52.778863Z","shell.execute_reply.started":"2024-08-16T11:45:52.229388Z","shell.execute_reply":"2024-08-16T11:45:52.777878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_msk = cv2.imread(\"/kaggle/input/kvasir-seg/Kvasir-SEG/masks/cju0qkwl35piu0993l0dewei2.jpg\") #3 channels / spectral bands\nplt.imshow(temp_msk)\n# temp_msk.shape\n\nlabels, count = np.unique(temp_msk, return_counts=True)\nprint(\"Labels are: \", labels, \" and the counts are: \", count)\nprint(temp_msk.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:45:52.780251Z","iopub.execute_input":"2024-08-16T11:45:52.780582Z","iopub.status.idle":"2024-08-16T11:45:53.083094Z","shell.execute_reply.started":"2024-08-16T11:45:52.780554Z","shell.execute_reply":"2024-08-16T11:45:53.082219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(path, split=0.1):\n    images = sorted(glob(os.path.join(path, \"image/*\")))\n    masks = sorted(glob(os.path.join(path, \"mask/*\")))\n\n    total_size = len(images)\n    valid_size = int(split * total_size)\n    test_size = int(split * total_size)\n\n    train_x, valid_x = train_test_split(images, test_size=valid_size, random_state=42)\n    train_y, valid_y = train_test_split(masks, test_size=valid_size, random_state=42)\n\n    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n\ndef read_image(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (256, 256))\n    x = x/255.0\n    return x\n\ndef read_mask(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (256, 256))\n    x = x/255.0\n    x = np.expand_dims(x, axis=-1)\n    return x\n\ndef tf_parse(x, y):\n    def _parse(x, y):\n        x = read_image(x)\n        y = read_mask(y)\n        return x, y\n\n    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n    x.set_shape([256, 256, 3])\n    y.set_shape([256, 256, 1])\n    return x, y\n\ndef tf_dataset(x, y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.map(tf_parse)\n    dataset = dataset.batch(batch)\n    dataset = dataset.repeat()\n    return dataset\n\n#a = read_image('/kaggle/input/kvasir-seg/Kvasir-SEG/images/cju0qkwl35piu0993l0dewei2.jpg')\n#a =  ['/kaggle/input/kvasir-seg/Kvasir-SEG/images/cju7do8c72dbo0801vxfzxdc4.jpg', '/kaggle/input/kvasir-seg/Kvasir-SEG/images/cju8cgi2kspp308011nxdtjp6.jpg', '/kaggle/input/kvasir-seg/Kvasir-SEG/images/cju7dxffn2eam0817qxosfwch.jpg', '/kaggle/input/kvasir-seg/Kvasir-SEG/images/cju88rl5eo94l0850kf5wtrm1.jpg']\n#dataset = tf.data.Dataset.from_tensor_slices(a)\n#for item in dataset:\n #   print(item.numpy().decode('utf-8')) ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-16T11:45:55.342069Z","iopub.execute_input":"2024-08-16T11:45:55.342869Z","iopub.status.idle":"2024-08-16T11:45:55.355409Z","shell.execute_reply.started":"2024-08-16T11:45:55.342835Z","shell.execute_reply":"2024-08-16T11:45:55.354543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\n\ndef conv_block(x, num_filters):\n    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x\n\ndef build_model():\n    size = 256\n    #num_filters = [32, 64, 128, 256 , 512]\n    num_filters = [64,128, 256, 512 , 1024]\n    inputs = Input((size, size, 3))\n\n    skip_x = []\n    x = inputs\n    ## Encoder\n    for f in num_filters:\n        x = conv_block(x, f)\n        skip_x.append(x)\n        x = MaxPool2D((2, 2))(x)\n\n    ## Bridge\n    x = conv_block(x, num_filters[-1])\n\n    num_filters.reverse()\n    skip_x.reverse()\n    ## Decoder\n    for i, f in enumerate(num_filters):\n        x = UpSampling2D((2, 2))(x)\n        xs = skip_x[i]\n        x = Concatenate()([x, xs])\n        x = conv_block(x, f)\n\n    ## Output\n    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n    x = Activation(\"sigmoid\")(x)\n\n    return Model(inputs, x)\n\n\nif __name__ == \"__main__\":\n    model = build_model()\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:46:08.453245Z","iopub.execute_input":"2024-08-16T11:46:08.453697Z","iopub.status.idle":"2024-08-16T11:46:11.170730Z","shell.execute_reply.started":"2024-08-16T11:46:08.453659Z","shell.execute_reply":"2024-08-16T11:46:11.169812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nfrom glob import glob\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\ndef mean_dice(y_true, y_pred):\n    def f(y_true, y_pred):\n        intersection = (y_true * y_pred).sum()\n        dice = (2. * intersection + 1e-15) / (y_true.sum() + y_pred.sum() + 1e-15)\n        dice = dice.astype(np.float32)\n        return dice\n    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n\n\ndef s_measure(y_true, y_pred, alpha=0.5):\n    def f(y_true, y_pred):\n        # Object-aware structural similarity\n        intersection = (y_true * y_pred).sum()\n        union = y_true.sum() + y_pred.sum() - intersection\n        s_object = (intersection + 1e-15) / (union + 1e-15)\n        \n        # Region-aware structural similarity\n        y_true_mean = y_true.mean()\n        y_pred_mean = y_pred.mean()\n        s_region = 1 - np.abs(y_true_mean - y_pred_mean)\n        \n        # S-measure\n        s_measure = alpha * s_object + (1 - alpha) * s_region\n        return s_measure.astype(np.float32)\n    \n    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n\n\n\ndef iou(y_true, y_pred):\n    def f(y_true, y_pred):\n        intersection = (y_true * y_pred).sum()\n        union = y_true.sum() + y_pred.sum() - intersection\n        x = (intersection + 1e-15) / (union + 1e-15)\n        x = x.astype(np.float32)\n        return x\n    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n\n\ndef max_e_measure(y_true, y_pred):\n    def f(y_true, y_pred):\n        y_true = y_true.astype(np.float32)\n        y_pred = y_pred.astype(np.float32)\n        \n        # Mean value of the ground truth\n        mean_gt = y_true.mean()\n        \n        # Enhanced alignment matrix\n        enhanced_matrix = 2 * y_pred / (y_pred + 1)\n        \n        # Pixel-level E-measure\n        e_matrix = (1 + enhanced_matrix) * y_true / (enhanced_matrix + y_true)\n        \n        # Max E-measure\n        e_max = e_matrix.max()\n        \n        return e_max.astype(np.float32)\n    \n    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n\n\ndef weighted_f_measure(y_true, y_pred, beta=1):\n    def f(y_true, y_pred):\n        y_true = y_true.astype(np.float32)\n        y_pred = y_pred.astype(np.float32)\n        \n        # Precision and Recall\n        tp = (y_true * y_pred).sum()\n        precision = tp / (y_pred.sum() + 1e-15)\n        recall = tp / (y_true.sum() + 1e-15)\n        \n        # Weighted F-measure\n        beta_squared = beta ** 2\n        f_measure = (1 + beta_squared) * (precision * recall) / (beta_squared * precision + recall + 1e-15)\n        \n        return f_measure.astype(np.float32)\n    \n    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:46:22.777014Z","iopub.execute_input":"2024-08-16T11:46:22.777387Z","iopub.status.idle":"2024-08-16T11:46:22.795195Z","shell.execute_reply.started":"2024-08-16T11:46:22.777355Z","shell.execute_reply":"2024-08-16T11:46:22.794232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    ## Dataset\n    path = \"/kaggle/input/polyp-data/TrainDataset/TrainDataset\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n    ## Hyperparameters\n    batch = 8\n    lr = 1e-4\n    epochs = 100\n\n    train_dataset = tf_dataset(train_x, train_y, batch=batch)\n    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)\n    print(train_dataset.element_spec)\n    print(valid_dataset.element_spec)\n#     print(train_x.element_spec)\n\n    model = build_model()\n\n    opt = tf.keras.optimizers.Adam(lr)\n    metrics = [\"acc\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), iou, s_measure, mean_dice, max_e_measure, weighted_f_measure]\n    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=metrics)\n\n    callbacks = [\n        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False),\n        ModelCheckpoint(\"model.h5\", save_best_only=True)\n    ]\n\n    train_steps = len(train_x)//batch\n    valid_steps = len(valid_x)//batch\n\n    if len(train_x) % batch != 0:\n        train_steps += 1\n    if len(valid_x) % batch != 0:\n        valid_steps += 1","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:49:58.739975Z","iopub.execute_input":"2024-08-16T11:49:58.740676Z","iopub.status.idle":"2024-08-16T11:50:00.054559Z","shell.execute_reply.started":"2024-08-16T11:49:58.740637Z","shell.execute_reply":"2024-08-16T11:50:00.053524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" model.fit(train_dataset,\n        validation_data=valid_dataset,\n        epochs=epochs,\n        steps_per_epoch=train_steps,\n        validation_steps=valid_steps,\n        callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T11:50:03.767373Z","iopub.execute_input":"2024-08-16T11:50:03.767986Z","iopub.status.idle":"2024-08-16T12:36:52.489833Z","shell.execute_reply.started":"2024-08-16T11:50:03.767953Z","shell.execute_reply":"2024-08-16T12:36:52.488832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score\ndef read_image(path):\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (256, 256))\n    x = x/255.0\n    return x\n\ndef read_mask(path):\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (256, 256))\n    x = x/255.0\n    x = np.expand_dims(x, axis=-1)\n    return x\n\ntest_images = [read_image(path) for path in test_x]\ntest_images = np.array(test_images)\n\nprediction_test = model.predict(test_images, batch_size=8)\n\ntrue_labels = [read_mask(path) for path in test_y]\ntrue_labels = np.array(true_labels)\n\nbinary_predictions = (prediction_test > 0.5).astype(int)\ny_test_bool = (true_labels > 0.5).astype(bool)\naccuracy_test = accuracy_score(np.ndarray.flatten(y_test_bool), np.ndarray.flatten(binary_predictions))\npresision_score_test = precision_score(np.ndarray.flatten(y_test_bool), np.ndarray.flatten(binary_predictions))\nrecall_score_test = recall_score(np.ndarray.flatten(y_test_bool), np.ndarray.flatten(binary_predictions))\n\n\nprint(f'accuracy: {accuracy_test * 100:.2f}%')\nprint(f'Precision:  {presision_score_test * 100:.2f}%')\nprint(f'Recall : {recall_score_test * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-08-16T12:57:08.088993Z","iopub.execute_input":"2024-08-16T12:57:08.089380Z","iopub.status.idle":"2024-08-16T12:57:22.080709Z","shell.execute_reply.started":"2024-08-16T12:57:08.089349Z","shell.execute_reply":"2024-08-16T12:57:22.079592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfirst_10_images = test_images[:10]\nfirst_10_true_labels = true_labels[:10]\nfirst_10_predictions = binary_predictions[:10]\n\nfor i in range(10):\n    plt.figure(figsize=(12, 4))\n\n    plt.subplot(1, 3, 1)\n    plt.imshow(first_10_images[i][...,::-1])\n    plt.title('Image')\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(first_10_true_labels[i], cmap='gray')\n    plt.title('Ground Truth')\n\n    plt.subplot(1, 3, 3)\n    plt.imshow(first_10_predictions[i], cmap='gray')\n    plt.title('Predicted')\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T12:58:10.984112Z","iopub.execute_input":"2024-08-16T12:58:10.985084Z","iopub.status.idle":"2024-08-16T12:58:17.249374Z","shell.execute_reply.started":"2024-08-16T12:58:10.985051Z","shell.execute_reply":"2024-08-16T12:58:17.248442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The below code is for the testing of the UNet model with a CVC-300 polyp dataset**.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score\n\ndef load_data2(path, split=0.1):\n    images = sorted(glob(os.path.join(path, \"images/*\")))\n    masks = sorted(glob(os.path.join(path, \"masks/*\")))\n\n    total_size = len(images)\n    valid_size = int(split * total_size)\n    test_size = int(split * total_size)\n\n    train_x, valid_x = train_test_split(images, test_size=valid_size, random_state=42)\n    train_y, valid_y = train_test_split(masks, test_size=valid_size, random_state=42)\n\n    return (train_x, train_y)\n\ndef read_image(path):\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (256, 256))\n    x = x/255.0\n    return x\n\ndef read_mask(path):\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (256, 256))\n    x = x/255.0\n    x = np.expand_dims(x, axis=-1)\n    return x\n\n\npath2 = \"/kaggle/input/polyp-data/TestDataset/TestDataset/CVC-300\"\n(test_x_cvc_300, test_y_cvc_300) = load_data2(path2)\n\ntest_images_cvc_300 = [read_image(path2) for path2 in test_x_cvc_300]\ntest_images_cvc_300 = np.array(test_images_cvc_300)\nprediction_test_cvc_300 = model.predict(test_images_cvc_300, batch_size=8)\n\n\ntrue_labels_cvc_300 = [read_mask(path2) for path2 in test_y_cvc_300]\ntrue_labels_cvc_300 = np.array(true_labels_cvc_300)\n\nbinary_predictions_cvc_300 = (prediction_test_cvc_300 > 0.5).astype(int)\ny_test_bool_cvc_300 = (true_labels_cvc_300 > 0.5).astype(bool)\naccuracy_test_cvc_300 = accuracy_score(np.ndarray.flatten(y_test_bool_cvc_300), np.ndarray.flatten(binary_predictions_cvc_300))\npresision_score_test_cvc_300 = precision_score(np.ndarray.flatten(y_test_bool_cvc_300), np.ndarray.flatten(binary_predictions_cvc_300))\nrecall_score_test_cvc_300 = recall_score(np.ndarray.flatten(y_test_bool_cvc_300), np.ndarray.flatten(binary_predictions_cvc_300))\n\n\nprint(f'accuracy_cvc_300: {accuracy_test_cvc_300 * 100:.2f}%')\nprint(f'Precision_cvc_300:  {presision_score_test_cvc_300 * 100:.2f}%')\nprint(f'Recall_cvc_300 : {recall_score_test_cvc_300 * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-08-16T13:36:33.170724Z","iopub.execute_input":"2024-08-16T13:36:33.171484Z","iopub.status.idle":"2024-08-16T13:36:44.502618Z","shell.execute_reply.started":"2024-08-16T13:36:33.171451Z","shell.execute_reply":"2024-08-16T13:36:44.501509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfirst_6_images = test_images_cvc_300[:6]\nfirst_6_true_labels = true_labels_cvc_300[:6]\nfirst_6_predictions = binary_predictions_cvc_300[:6]\n\nfor i in range(10):\n    plt.figure(figsize=(12, 4))\n\n    plt.subplot(1, 3, 1)\n    plt.imshow(first_6_images[i][...,::-1])\n    plt.title('CVC-300 Image')\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(first_6_true_labels[i], cmap='gray')\n    plt.title('Ground Truth')\n\n    plt.subplot(1, 3, 3)\n    plt.imshow(first_6_predictions[i], cmap='gray')\n    plt.title('Predicted')\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T13:38:35.786760Z","iopub.execute_input":"2024-08-16T13:38:35.787490Z","iopub.status.idle":"2024-08-16T13:38:39.560890Z","shell.execute_reply.started":"2024-08-16T13:38:35.787459Z","shell.execute_reply":"2024-08-16T13:38:39.559598Z"},"trusted":true},"execution_count":null,"outputs":[]}]}